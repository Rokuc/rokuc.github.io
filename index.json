
    
    
    [{"authors":null,"categories":null,"content":"During my professional career, I acquired solid experience in data engineering and data analysis. Moreover, I have experience in visualizing and modeling data in PowerBI.\nIn addition to this I have project management experience and am familiar with the scrum methodology.\nWhen I don’t work on any projects I like to travel and dive.\nDownload my resumé .\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"During my professional career, I acquired solid experience in data engineering and data analysis. Moreover, I have experience in visualizing and modeling data in PowerBI.\nIn addition to this I have project management experience and am familiar with the scrum methodology.","tags":null,"title":"Rok Jankovic","type":"authors"},{"authors":null,"categories":null,"content":"Project overview ","date":1671580800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1671580800,"objectID":"c3d1f729df78dfbbf51124c634d4e9d5","permalink":"https://rokuc.github.io/project/customer-lifetime-value/","publishdate":"2022-12-21T00:00:00Z","relpermalink":"/project/customer-lifetime-value/","section":"project","summary":"In this project we wanted to calculate customer lifetime value. Moreover we wanted the model to be visualized in a dashboard and allow colleagues to activate audiences based on selected parameters in the dashboard. Feel free to read a short summary about this project. In this article we will cover the analytics behind the project.","tags":["Data Analysis"],"title":"Customer Lifetime Value - Analysis - Part 1","type":"project"},{"authors":null,"categories":null,"content":"Project overview Our team developed a Dashboard for multiple stakeholders. While the users were happy with the dashboard, manual pipelines were time-consuming. To enhance efficiency, our team decided to create an automated crawler to directly populate a database with the same data previously stored as CSV files on SharePoint. The crawler was set to run daily through the Windows Task Scheduler which triggered batch scripts every morning.\nChallenges faced while working on the crawler:\nAvoiding Frequent Crashes: Initial problem was preventing crashes from frequent clicks. We tackled it using try-except blocks and loops. Handling Dynamic Website Changes: Adapting to website changes was tough. We made it work by spotting elements through their inner text. Getting Crawler Status Updates: Knowing when the crawler ran or crashed was tricky. We nailed it by setting up automatic emails reporting on the latest date available in our dataset. ","date":1647302400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1647302400,"objectID":"717ed199343f1dfe291e2f3cda6dc3b1","permalink":"https://rokuc.github.io/project/e-store-crawler/","publishdate":"2022-03-15T00:00:00Z","relpermalink":"/project/e-store-crawler/","section":"project","summary":"In this project I supported our team in the implementation of an autonomous web crawler. First we collected data from the web. After collecting and transforming the data the data was mapped to a database. Feel free to read a short summary about this project.","tags":["Data Engineering"],"title":"An autonomous web crawler","type":"project"}]